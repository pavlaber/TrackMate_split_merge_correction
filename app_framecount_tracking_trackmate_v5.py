# -*- coding: utf-8 -*-
"""APP_frameCount_tracking_trackmate_V5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BcejqUo9Kd9aNTdVZmdGZejV_VWuTH28

Change log V5:
* some of tracking have multiple split, which will affect long splits
* adding column *split_sum_check* to flag them
* end counting with another split

**last edit: 16.3.2022**

Change log V4a:
* add tag for short split with and without merge
* add tag for long split with and without merge

**last edit: 10.3.2022**

Change log V4:
* min track length problem
* count/add long splits [TODO: check results]

**last edit: 28.2.2022**

Change log V3:
* do not count short splits that are not merged back
* add number of splits to output, based on information from tracks
* add table output, spots count for track based on frame/time

**last edit: 19.1.2022**

https://forum.image.sc/t/trackmate-parse-exact-relationships-of-splitting-events-within-each-track/30487/6
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import numpy as np
from collections import Counter

#@markdown Path to directory (needs to be specified by user)
datadir = "/content/gdrive/MyDrive/Python/tracking_analysis/data/set1/"  #@param {type: "string"}
#@markdown ---
#@markdown Default Trackmate file names
tracks_name = "tracks_table.csv" #@param {type: "string"}
edges_name = "edges_table.csv" #@param {type: "string"}
spots_name = "spots_table.csv" #@param {type: "string"}

tracks = pd.read_csv(datadir+tracks_name,\
                     usecols = ['NUMBER_SPOTS', 'NUMBER_GAPS', 'LONGEST_GAP', 'NUMBER_SPLITS', 'TRACK_ID'])
links = pd.read_csv(datadir+edges_name, \
                    usecols = ['LABEL', 'TRACK_ID', 'SPOT_SOURCE_ID', 'SPOT_TARGET_ID', 'EDGE_X_LOCATION', \
                               'EDGE_Y_LOCATION'])
spots = pd.read_csv(datadir+spots_name,\
                    usecols = ['LABEL', 'ID', 'TRACK_ID', 'POSITION_X', 'POSITION_Y', 'FRAME'])

# tracks.head()

tracks.describe()

#@title
# links.head()

"""Generate a list of spot_ids that correspond to a splitting event"""

#@title
# Generate a list of spot_ids that correspond to a splitting event
# (SOURCE_IDs of splitting event appear twice)

source_ids = list(links["SPOT_SOURCE_ID"])
source_id_counts = Counter(source_ids)
splitting_event_ids = [id for id in source_id_counts if source_id_counts[id] > 1]

merge_ids = list(links["SPOT_TARGET_ID"])
merge_id_counts = Counter(merge_ids)
merging_event_ids = [id for id in merge_id_counts if merge_id_counts[id] > 1]

# Add Boolean to Spots and Links Dataframes

spots["Splitting_event"] = spots["ID"].apply(lambda x:\
                                             False if x not in splitting_event_ids\
                                             else True)

links["Splitting_event"] = links["SPOT_SOURCE_ID"].apply(lambda x:\
                                             False if x not in splitting_event_ids\
                                             else True)

links["Merging_event"] = links["SPOT_TARGET_ID"].apply(lambda x:\
                                             False if x not in merging_event_ids\
                                             else True)
# Rename link dataframe columns

links.columns = ['LABEL',\
                 'TRACK_ID',\
                 'SOURCE_ID',\
                 'TARGET_ID',\
                 'EDGE_X_LOCATION',\
                 'EDGE_Y_LOCATION',\
                 'SPLITTING_EVENT',\
                 "MERGING_EVENT"]

spots.head()

links.head()

"""Create a time-spreadsheat for visual inspection of number of spots in each track"""

#@title
# retype to int, from 4th
number_column = spots.loc[3::,'FRAME'].astype(int)
maxFrame=number_column.max()
print("Number of time frames",maxFrame)

d = {'1': np.zeros(maxFrame)}
numTracks = pd.DataFrame(data=d)


N=tracks.iloc[3::]['TRACK_ID'].count()
#print(N)
for id in range(0,N):
  numTracks.insert(id, tracks.iloc[3+id]['TRACK_ID'], np.zeros(maxFrame), True)
  #print(tracks.iloc[3+id]['TRACK_ID'])

"""add merging events to links"""

#@title
from pandas.core.dtypes.cast import maybe_infer_to_datetimelike
for id in range(0,N):
  # go through all tracks
  id_num=tracks.iloc[3+id]['TRACK_ID']

  #select spots only for one id
  spots_ID=spots[spots['TRACK_ID']==id_num]
  links_ID=links[links['TRACK_ID']==id_num]

  #print(minFrame, maxFrame)
  # inspect only tracks with splits
  TC=len(spots_ID)
  if TC>0:
    #print(TC)
    minFrame=int(spots_ID['FRAME'].min())
    maxFrame=int(spots_ID['FRAME'].max())
    for fr in range(minFrame,maxFrame):
      nFrames=spots_ID[spots_ID['FRAME']==str(fr)]
      numTracks.at[fr,id_num]=len(nFrames)
      #print(fr, len(nFrames))

numTracks.head()

"""## Look for splits and merges in each track"""

#@title int(c), merge, split = findLinks(start_ID, links_ID, splitCut) 
def findLinks(start_ID, links_ID, splitCut) -> int:
  c=1
  merge=False
  split=False
  # find link which has first spot id as source
  link=links_ID[links_ID['SOURCE_ID']==start_ID]

  if len(link)>0:
    # find where it leads
    start_ID=link['TARGET_ID'].values[0]

    # repeat until merge or end is found
    while len(link)>0: #(link['MERGING_EVENT'].values[0]==False) & len(link)>0:
      # check for merge
      if (link['MERGING_EVENT'].values[0]==True):
        merge=True
        break
      #  check for split, but after merge - megre has prioritz in counting steps
      if splitCut:
        if (link['SPLITTING_EVENT'].values[0]==True):
          print('Spliting again at', start_ID)
          split=True
          break
      # find link which has first spot id as source
      try:
        link=links_ID[links_ID['SOURCE_ID']==start_ID]
        if len(link)==0:
          break
      except:
        break
      
      # find where it leads
      start_ID=link['TARGET_ID'].values[0]
      c=c+1;
    return int(c), merge, split
  else:
    return 0, merge, split

#@title unique function
# function to get unique values
def unique(list1):
 
    # initialize a null list
    unique_list = []
     
    # traverse for all elements
    for x in list1:
        # check if exists in unique_list or not
        if x not in unique_list:
            unique_list.append(x)
    return unique_list

"""* short_split: <th without merge
* short_split_merge: <th and merge
* long_split: >th without merge
* long_split_merge: >th and merge
"""

#@title
tracks['short_split'] = 0
tracks['short_split_merge'] = 0
tracks['num_splits'] = 0
tracks['num_merges'] = 0
tracks['long_split'] = 0
tracks['long_split_merge'] = 0
tracks['split_sum_check'] = 0
#tracks['short_split'].values[0]='Number of short splits'
#tracks['short_split'].values[1]='shorter then 2 frames'
#tracks['long_split'].values[0]='Number of long splits'
#tracks['long_split'].values[1]='longer then 2 frames'

#@markdown Definu number of frames in from split to megre to be defined as short split
short_split_length=3 #@param {type: "slider", min: 2, max: 20}
#@markdown End counting with another split event
splitCut = False  #@param {type: "boolean"}


#for id in range(0,N):
for id in range(0,N):
  # go through all tracks
  id_num=tracks.iloc[3+id]['TRACK_ID']
  print('--------------------')
  print('Track ID', id_num)

  #select spots only for one id
  spots_ID=spots[spots['TRACK_ID']==id_num]
  # mask = mask = spots_ID['FRAME'].isin(['6','5','4','3','2','1'])
  # spots_ID=spots_ID[mask]

  links_ID=links[links['TRACK_ID']==id_num]


  # select spliting links only
  links_ID_split=links_ID[links_ID['SPLITTING_EVENT']==True]
  print('num links: ',len(links_ID_split))
  num=[]
  mergeT=[]
  splitT=[]

  # check if there is any split
  if len(links_ID_split)>0:
    # inspect every spliting link
    for Tid in range(0,len(links_ID_split)):
      start_ID=links_ID_split['TARGET_ID'].values[Tid]
      # check if it exists
      if len(start_ID)>1: 
        numLinks, mergeTag, splitTag = findLinks(start_ID, links_ID,splitCut)
        num.append(numLinks)
        mergeT.append(mergeTag)
        splitT.append(splitTag)

    print('Start ID: ',start_ID, ', tracing: ', num) #, ' merge', mergeTag)
    print(mergeT)
    print(splitT)

    #shortS = [n for n in num if n <=short_split_length]
    shortS = [n for i,n in enumerate(num) if n <=short_split_length and not mergeT[i] and not splitT[i]]
    shortSmerge = [n for i,n in enumerate(num) if n <=short_split_length and mergeT[i] and not splitT[i]]
    shortSsplit = [n for i,n in enumerate(num) if n <=short_split_length and splitT[i]]
    #longS = [n for n in num if n >short_split_length]
    longS = [n for i,n in enumerate(num) if n >short_split_length and not mergeT[i] and not splitT[i]]
    longSmerge = [n for i,n in enumerate(num) if n >short_split_length and mergeT[i] and not splitT[i]]
    longSsplit = [n for i,n in enumerate(num) if n >short_split_length and splitT[i]]
    
    # we will have two times of short splits, since we end counting at merge
    tracks['short_split'].values[3+id]=len(shortS)#max(len(shortS)/2-len(shortSmerge)/2,0)
    tracks['short_split_merge'].values[3+id] = len(shortSmerge)/2 #- len(shortSsplit)

    #long split (to be checked)
    tracks['long_split'].values[3+id]=len(longS)#max(len(longS)/2-(len(shortS)/2)-len(longSmerge)/2,0)
    tracks['long_split_merge'].values[3+id] = len(longSmerge)/2 #- len(longSsplit)

    split=links_ID[links_ID['SPLITTING_EVENT']==True]
    links_splitU=split["SOURCE_ID"].tolist()
    # number of splits
    tracks['num_splits'].values[3+id]=len(unique(links_splitU))

    merge=links_ID[links_ID['MERGING_EVENT']==True]
    links_mergedU=merge["TARGET_ID"].tolist()
    # number of merges
    tracks['num_merges'].values[3+id]=len(unique(links_mergedU))

    tracks['split_sum_check'].values[3+id]=tracks['num_splits'].values[3+id]-tracks['short_split'].values[3+id]-tracks['short_split_merge'].values[3+id]-tracks['long_split'].values[3+id]-tracks['long_split_merge'].values[3+id]

#@title
# if len(links_ID_split)>0:
#     # inspect every spliting link
#     for Tid in range(0,len(links_ID_split)):
#       start_ID=links_ID_split['TARGET_ID'].values[Tid]
#       # check if it exists
#       if len(start_ID)>1: 
#         numLinks, mergeTag = findLinks(start_ID, links_ID)
#         print("Steps found: ", numLinks)
#         print("Tag:", mergeTag)

"""## Inspect results"""

tracks[tracks["TRACK_ID"]=='2']

#@title
tracks

#@title
# #@title
# sel=tracks['TRACK_ID']=='40'
# #tracks[sel]
# tracks[sel]

"""## Export result to csv"""

output_name = "tracks_output.xlsx" #@param {type: "string"}
tracks.to_excel(output_name,
             sheet_name='Tracks_analysis')

frames_output_name = "timeFrames_output.xlsx" #@param {type: "string"}
numTracks.to_excel(frames_output_name,
             sheet_name='Tracks_analysis')